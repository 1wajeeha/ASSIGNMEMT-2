{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f17d4b1d-6118-42d4-b20f-4931a6f6033c",
   "metadata": {},
   "source": [
    "# Dataset 1 Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e63a668-fb54-42ea-8bb4-be09a8606a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a0fe81-8d2b-4088-bf83-d7172ea5a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/wajeehaqurban/Downloads/healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bea59c-2d15-4c1d-a257-63ad77f23754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " id                    0\n",
      "gender                0\n",
      "age                   0\n",
      "hypertension          0\n",
      "heart_disease         0\n",
      "ever_married          0\n",
      "work_type             0\n",
      "Residence_type        0\n",
      "avg_glucose_level     0\n",
      "bmi                  46\n",
      "smoking_status        0\n",
      "stroke                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b74de0a-56a1-4f39-937d-013f8bad484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/csn3vqcs73jg7h2l_sbksz3h0000gp/T/ipykernel_4084/1356004017.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['bmi'].fillna(data['bmi'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['bmi'].fillna(data['bmi'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a68821e-e928-4b24-a527-44ac22a5dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f12167a-e826-45dc-a8a8-de8d7d373813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = label_encoder.fit_transform(data['gender'])\n",
    "data['ever_married'] = label_encoder.fit_transform(data['ever_married'])\n",
    "data['work_type'] = label_encoder.fit_transform(data['work_type'])\n",
    "data['Residence_type'] = label_encoder.fit_transform(data['Residence_type'])\n",
    "data['smoking_status'] = label_encoder.fit_transform(data['smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6e1b51-84a1-42b7-8ca7-c8e9cab21b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d6b3c6-4755-40ab-abeb-3440b2ff82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = scaler.fit_transform(data[['age']])\n",
    "data['bmi'] = scaler.fit_transform(data[['bmi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4b73e7-d994-46aa-972c-85d76988317b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Sample:\n",
      "       id  gender       age  hypertension  heart_disease  ever_married  \\\n",
      "0   9046       1  0.634926             0              1             1   \n",
      "1  51676       0  0.365898             0              0             1   \n",
      "2  31112       1  1.217818             0              1             1   \n",
      "3  60182       0 -0.172157             0              0             1   \n",
      "4   1665       0  1.172980             1              0             1   \n",
      "\n",
      "   work_type  Residence_type  avg_glucose_level           bmi  smoking_status  \\\n",
      "0          2               1             228.69  8.571905e-01               1   \n",
      "1          3               0             202.21 -4.660478e-16               2   \n",
      "2          2               0             105.92  3.193492e-01               2   \n",
      "3          2               1             171.23  5.685927e-01               3   \n",
      "4          3               0             174.12 -7.956876e-01               2   \n",
      "\n",
      "   stroke  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "print(\"Processed Data Sample:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95514338-ffd9-42e4-aadf-e0cb0ea5e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef4205b-8263-4cb9-9917-4563c19fcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, random_state=0)\n",
    "data['KMeans_Cluster'] = kmeans.fit_predict(data.drop(columns=['stroke']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022d5359-6f5c-49d1-a4b7-cd2f593ab3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical = AgglomerativeClustering(n_clusters=6)\n",
    "data['Hierarchical_Cluster'] = hierarchical.fit_predict(data.drop(columns=['stroke']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43c28d04-8465-43ae-af76-016d342ff503",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_kmeans = silhouette_score(data.drop(columns=['KMeans_Cluster', 'Hierarchical_Cluster', 'stroke']), data['KMeans_Cluster'])\n",
    "silhouette_hierarchical = silhouette_score(data.drop(columns=['KMeans_Cluster', 'Hierarchical_Cluster', 'stroke']), data['Hierarchical_Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35841c5f-8265-478b-981c-bc5bd1c2f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "davies_bouldin_kmeans = davies_bouldin_score(data.drop(columns=['KMeans_Cluster', 'Hierarchical_Cluster', 'stroke']), data['KMeans_Cluster'])\n",
    "davies_bouldin_hierarchical = davies_bouldin_score(data.drop(columns=['KMeans_Cluster', 'Hierarchical_Cluster', 'stroke']), data['Hierarchical_Cluster'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e3975ad-c803-436e-bd67-10083b8bc2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Validation Results:\n",
      "Silhouette Score (K-Means): 0.5705170254033136\n",
      "Silhouette Score (Hierarchical): 0.5427741690805332\n",
      "Davies-Bouldin Index (K-Means): 0.49793292576134296\n",
      "Davies-Bouldin Index (Hierarchical): 0.5023108011070582\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"Clustering Validation Results:\")\n",
    "print(f\"Silhouette Score (K-Means): {silhouette_kmeans}\")\n",
    "print(f\"Silhouette Score (Hierarchical): {silhouette_hierarchical}\")\n",
    "print(f\"Davies-Bouldin Index (K-Means): {davies_bouldin_kmeans}\")\n",
    "print(f\"Davies-Bouldin Index (Hierarchical): {davies_bouldin_hierarchical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57bd61ec-4863-41cf-81ea-fb56ba23078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X = data.drop(columns=['stroke', 'KMeans_Cluster', 'Hierarchical_Cluster'])\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a834a3-2baf-45d1-ba66-3b7794999523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Number of Components: 10\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=0.95, random_state=0)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "pca_components = X_pca.shape[1]\n",
    "print(f\"PCA Number of Components: {pca_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b4c74a-97b0-4bb7-8e6e-ee57e699914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Selected Features: ['age', 'hypertension', 'heart_disease', 'ever_married', 'avg_glucose_level']\n"
     ]
    }
   ],
   "source": [
    "X_non_negative = MinMaxScaler().fit_transform(X)\n",
    "chi2_selector = SelectKBest(chi2, k=5)\n",
    "X_chi2 = chi2_selector.fit_transform(X_non_negative, y)\n",
    "chi2_selected_features = X.columns[chi2_selector.get_support(indices=True)]\n",
    "print(\"Chi-Square Selected Features:\", chi2_selected_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02801c64-2cd5-4a43-b6f8-c1a36c86c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_supervised = data.drop(columns=['stroke'])  # Drop the target column to create X\n",
    "y = data['stroke']  # Define the target variable\n",
    "\n",
    "# Impute missing values with mean (for numerical) and mode (for categorical)\n",
    "X_imputed = X_supervised.apply(lambda col: col.fillna(col.mean()) if col.dtype != 'object' else col.fillna(col.mode()[0]))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc2563e-0385-459c-aaa1-87fe97e6b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4b11f9-ca67-40e4-8558-9e411eb8d244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Accuracy: 0.7333333333333333\n",
      "Precision: 0.6708860759493671\n",
      "Recall: 0.7066666666666667\n",
      "F1-Score: 0.6883116883116883\n",
      "Confusion Matrix:\n",
      " [[79 26]\n",
      " [22 53]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77       105\n",
      "           1       0.67      0.71      0.69        75\n",
      "\n",
      "    accuracy                           0.73       180\n",
      "   macro avg       0.73      0.73      0.73       180\n",
      "weighted avg       0.74      0.73      0.73       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=0)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_log_reg))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_log_reg))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62bb372e-f7c7-4eca-a103-58c175cf620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest\n",
      "Accuracy: 0.7277777777777777\n",
      "Precision: 0.6756756756756757\n",
      "Recall: 0.6666666666666666\n",
      "F1-Score: 0.6711409395973155\n",
      "Confusion Matrix:\n",
      " [[81 24]\n",
      " [25 50]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77       105\n",
      "           1       0.68      0.67      0.67        75\n",
      "\n",
      "    accuracy                           0.73       180\n",
      "   macro avg       0.72      0.72      0.72       180\n",
      "weighted avg       0.73      0.73      0.73       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"\\nRandom Forest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6bb2ff3-d68a-455b-9291-04f4745418de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine (SVM)\n",
      "Accuracy: 0.5833333333333334\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Confusion Matrix:\n",
      " [[105   0]\n",
      " [ 75   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       105\n",
      "           1       0.00      0.00      0.00        75\n",
      "\n",
      "    accuracy                           0.58       180\n",
      "   macro avg       0.29      0.50      0.37       180\n",
      "weighted avg       0.34      0.58      0.43       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define feature set and target variable\n",
    "X_supervised = data.drop(columns=['stroke'])  # Drop the target column to create X\n",
    "y = data['stroke']  # Define the target variable\n",
    "\n",
    "# Impute missing values with mean (for numerical) and mode (for categorical)\n",
    "X_imputed = X_supervised.apply(lambda col: col.fillna(col.mean()) if col.dtype != 'object' else col.fillna(col.mode()[0]))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Create and train SVM model\n",
    "svm = SVC(probability=True, random_state=0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate and print results\n",
    "print(\"\\nSupport Vector Machine (SVM)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_svm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_svm))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "343d2f6b-3cf4-4ee5-a3c0-061f2cd8acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Nearest Neighbors (KNN)\n",
      "Accuracy: 0.4666666666666667\n",
      "Precision: 0.34782608695652173\n",
      "Recall: 0.32\n",
      "F1-Score: 0.3333333333333333\n",
      "Confusion Matrix:\n",
      " [[60 45]\n",
      " [51 24]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.56       105\n",
      "           1       0.35      0.32      0.33        75\n",
      "\n",
      "    accuracy                           0.47       180\n",
      "   macro avg       0.44      0.45      0.44       180\n",
      "weighted avg       0.46      0.47      0.46       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"\\nK-Nearest Neighbors (KNN)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6403217e-fbc0-4517-b549-a246d0b5177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:18:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost\n",
      "Accuracy: 0.7444444444444445\n",
      "Precision: 0.6986301369863014\n",
      "Recall: 0.68\n",
      "F1-Score: 0.6891891891891891\n",
      "Confusion Matrix:\n",
      " [[83 22]\n",
      " [24 51]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78       105\n",
      "           1       0.70      0.68      0.69        75\n",
      "\n",
      "    accuracy                           0.74       180\n",
      "   macro avg       0.74      0.74      0.74       180\n",
      "weighted avg       0.74      0.74      0.74       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(\"\\nXGBoost\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_xgb))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec8ec0-c89b-406f-bf08-6e0ce9ca33de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d209d-f81d-41ca-ba47-ddb662b4aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
